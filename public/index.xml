<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>home on Lucas Roesler</title>
    <link>http://lucasroesler.com/index.xml</link>
    <description>Recent content in home on Lucas Roesler</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 14 Jan 2017 14:50:49 -0700</lastBuildDate>
    <atom:link href="http://lucasroesler.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How I Git</title>
      <link>http://lucasroesler.com/2017/03/how-i-git/</link>
      <pubDate>Sun, 19 Mar 2017 00:00:00 -0600</pubDate>
      
      <guid>http://lucasroesler.com/2017/03/how-i-git/</guid>
      <description>&lt;p&gt;Perhaps the one piece of ubiquitous technology that you will find at any new
tech company is &lt;code&gt;git&lt;/code&gt;.  There are a couple of other technologies that you will
probably find, like AWS, but &lt;code&gt;git&lt;/code&gt; is the only one I expect to find everywhere. It is
also, surprisingly, many developers number one frienemy.  I want to share some
of my favorite tips and tweaks that I have used over the years to make it all
friend and never my enemy.
&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s get this out of the way.  I like &lt;code&gt;git&lt;/code&gt;, a lot. I am one of the odd
people that think it makes sense. I can&amp;rsquo;t defend how complex it can sometimes
get, but I think that by and large the design and philosophy works for me and
I can do a lot with it.&lt;/p&gt;

&lt;h1 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h1&gt;

&lt;h2 id=&#34;branching&#34;&gt;Branching&lt;/h2&gt;

&lt;p&gt;Use 2 permanent branches &lt;code&gt;master&lt;/code&gt; and &lt;code&gt;develop&lt;/code&gt; with ephemeral branches for
&lt;code&gt;features&lt;/code&gt; and &lt;code&gt;hotfix&lt;/code&gt;es.  Many people will advocate for other branching
strategies but I think that this model is easy to convey and easy to mentally
track. All new code is merged into &lt;code&gt;develop&lt;/code&gt; and when you are ready to release
something you merge &lt;code&gt;develop&lt;/code&gt; into &lt;code&gt;master&lt;/code&gt; and then tag the HEAD of &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Need to fix a bug in production? Create a &lt;code&gt;hotfix&lt;/code&gt; branch off of &lt;code&gt;master&lt;/code&gt;,
merge that into &lt;code&gt;master&lt;/code&gt;, tag it, deploy, and then merge master back into
&lt;code&gt;develop&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Want to build the next cool feature? Create a &lt;code&gt;feature&lt;/code&gt; branch off of
&lt;code&gt;develop&lt;/code&gt; and then merge that back into &lt;code&gt;develop&lt;/code&gt; when you are done and move on
to the next hot thing.&lt;/p&gt;

&lt;p&gt;I like this pattern because it is simple and gives you quite a bit of control
over what happens when. I have seen many people advocate for a single &lt;code&gt;master&lt;/code&gt;
branch that everything goes into. But, unless you have really good test
coverage and are doing true continuous integration where every commit is
deployable; the single branch policy will eventually breakdown on a team of any
reasonable size. It simply requires a discipline that I haven&amp;rsquo;t seen larger
teams maintain.&lt;/p&gt;

&lt;p&gt;At Teem, we use one more semi-permanent branch we lovingly refer to as the
&lt;code&gt;release&lt;/code&gt; branch.  For each release (we release weekly) we branch off of
develop into a branch named &lt;code&gt;release-&amp;lt;version_num&amp;gt;&lt;/code&gt;.  We then deploy
this to a staging server for QA to validate. Having this additional branch
allows development of new features to keep going without causing a lot of
headache or confusion about what is in the release and if QA finds an issue,
how to merge the fix for that release.  Everything for that release is branched
from and merged back into the &lt;code&gt;release&lt;/code&gt; branch. Finally, when it is time to
release, we merge the &lt;code&gt;release&lt;/code&gt; branch into &lt;code&gt;master&lt;/code&gt; and tag the HEAD. Backport
&lt;code&gt;master&lt;/code&gt; into &lt;code&gt;develop&lt;/code&gt;, rinse and repeat.&lt;/p&gt;

&lt;h2 id=&#34;branch-names&#34;&gt;Branch names&lt;/h2&gt;

&lt;p&gt;Please, for the love of all that is good, use descriptive branch names. I
suggest the following naming patterns&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;feature-&amp;lt;ISSUE_ID&amp;gt;-short-summary-of-branch
hotfix-&amp;lt;ISSUE_ID&amp;gt;-short-summary-of-branch
releasefix-&amp;lt;ISSUE_ID&amp;gt;-short-summary-of-branch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Doing this allows anyone that is reviewing that branch to have some idea of
where that merge should be going, e.g. &lt;code&gt;feature&lt;/code&gt; branches merge into &lt;code&gt;develop&lt;/code&gt;
not &lt;code&gt;master&lt;/code&gt;.  Having the issue id (we use JIRA, but this could be the id from
any ticket tracker) allows people to reference what the branch should be
addressing, be that a bug report or a user story.  And finally, a short summary
makes the branch descriptive and easier to use. I also recommend this pattern
because it then becomes easy to create a changelog from the git log of merges.&lt;/p&gt;

&lt;h2 id=&#34;commit-messages&#34;&gt;Commit Messages&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s get the less contentious piece of advice out of the way, commit messages
should be informative and well structured.  I have generally followed the
advice of
&lt;a href=&#34;http://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html&#34;&gt;tpope&lt;/a&gt;
and the
&lt;a href=&#34;https://www.git-scm.com/book/en/v2/Distributed-Git-Contributing-to-a-Project#Commit-Guidelines&#34;&gt;&lt;code&gt;git&lt;/code&gt; handbook&lt;/a&gt;
but with a slight tweak. Here is a example commit message&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Capitalized, short (50 chars or less) summary

**What**
- Bullet pointed list of changes you made. 
- Each line should be no longer than 72 characters.
- For example:
- Switch from o365 beta API to the v1 API

**Why**
- Again a bulleted list of reasons you made that change.
- Again, no longer than 72 characters.
- For example:
- The v1 API is now stable and the beta API contains breaking changes with the
v1 api.

**Notes**
- Any additional notes for peer reviewers or to add additional context. 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The most important thing to remember, this message is supposed to inform people
about what is happening in the project without them needing to read every file.
For peer review, it is important that they can recognize what is intended to be
in the change set and what should not be there. One-line messages help no one.&lt;/p&gt;

&lt;p&gt;To help ensure that you write a half-decent commit message, &lt;code&gt;git&lt;/code&gt; has a feature
where called &lt;code&gt;.gitmessage&lt;/code&gt;.  Create a file called &lt;code&gt;.gitmessage&lt;/code&gt; in your home
folder and put this in it&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Captialized, short (50 chars or less) summary

**What**
-

**Why**
-

**Notes**
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;git&lt;/code&gt; will now use that as the template/initial text in all of your commit
messages.&lt;/p&gt;

&lt;p&gt;Note, it will not have any impact on specifying the commit message when using
&lt;code&gt;git -m&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;commits&#34;&gt;Commits&lt;/h2&gt;

&lt;p&gt;Something that is probably not so contentious: I believe in
committing frequently.  And now something slightly more contentious: I believe
in using rebase to create a sensible history that makes something like
&lt;code&gt;cherry-pick&lt;/code&gt; simple to use. I generally believe that you should work on small
chunks of code that can be reasonably described in a single commit with one or
two comments in the &amp;ldquo;What&amp;rdquo; section of my commit message. I also believe that
you should break coding style fixes, e.g PEP8 fixes, into separate commits so
that they can be reviewed separately. To actually make all of these ideas play
nicely together I use rebase frequently. I squash my frequent small commit into
larger (but still fairly small) semantic pieces of history, so my git log will
go from something like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sha1 - &amp;quot;Add new contact method&amp;quot;
sha2 - &amp;quot;Fix typo in contact method&amp;quot;
sha3 - &amp;quot;Add new unit test&amp;quot;
sha4 - &amp;quot;Fix bug found by unit test&amp;quot;
sha5 - &amp;quot;Fix PEP8 issues with imports&amp;quot;
sha6 - &amp;quot;Fix PEP8 issues with line lengths&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to something like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sha1&#39; - &amp;quot;Add new contact method and unit test&amp;quot;
sha2&#39; - &amp;quot;Fix PEP8 issues&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This history makes it easy to cherry-pick or revert the new feature and it
makes it easier for peer reviewers to review the logic change in &lt;code&gt;sah1&#39;&lt;/code&gt;
independently of the potentially noisy and distracting PEP8 changes in &lt;code&gt;sha2&#39;&lt;/code&gt;.
To do this I make heavy use &lt;code&gt;git rebase -i&lt;/code&gt; to selectively squash commits.  I
have also created an aliases called &lt;code&gt;git fixup&lt;/code&gt; that will simply squash my
staged changes into my previous commit. More on aliases later.&lt;/p&gt;

&lt;h2 id=&#34;on-rebasing&#34;&gt;On rebasing&lt;/h2&gt;

&lt;p&gt;I do not intend to give a full defense of rebasing here. I will say this; if
you are not comfortable with &lt;code&gt;git&lt;/code&gt;, then rebasing may not be for you.  Almost
everything else you do in &lt;code&gt;git&lt;/code&gt; is fairly safe, there is a way to recover from
what you are doing, this is why I like and trust &lt;code&gt;git&lt;/code&gt;.  However, &lt;code&gt;rebase&lt;/code&gt; is
one of those commands that is not always recoverable and you often have to
simply live with the end results. With that said, if you are using rebase
especially if you are using &lt;code&gt;pull -r&lt;/code&gt;, which is a standard pull that uses
rebase instead of merge, then you must enable and configure the &lt;code&gt;rerere&lt;/code&gt;
feature. Quick, update your &lt;code&gt;~/.gitconfig&lt;/code&gt; to have&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[rerere]
    enabled = 1
    autoupdate = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you will thank me. From the &lt;a href=&#34;https://git-scm.com/blog/2010/03/08/rerere.html&#34;&gt;git
book&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The name stands for &amp;ldquo;reuse recorded resolution&amp;rdquo; and as the name implies, it
 allows you to ask Git to remember how you&amp;rsquo;ve resolved a hunk conflict so
 that the next time it sees the same conflict, Git can automatically resolve
 it for you.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Basically, while you are rebasing, if you have a conflict that you resolve, git
will now remember that resolution and automatically apply it again in the
future.  This is huge for &lt;code&gt;git pull -r&lt;/code&gt;, which will often replay the same
section of your history and therefore run into the same conflict over and over.
Honestly, I don&amp;rsquo;t think rebase is usable without enabling &lt;code&gt;rerere&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;aliases&#34;&gt;Aliases&lt;/h1&gt;

&lt;p&gt;Any post on &lt;code&gt;git&lt;/code&gt; can not be complete without a list of handy-dandy aliases and
commands.  So, here are mine.  I have roughly 3 categories of aliases: audit
and cleanup, historical logging, and commit helpers.&lt;/p&gt;

&lt;h2 id=&#34;audit-and-cleanup&#34;&gt;Audit and cleanup&lt;/h2&gt;

&lt;p&gt;The following commands help me clean up old branches&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;audit = !git branch --merged | grep -v &#39;\*\|master\|develop\|release-&#39;
clean-audit = !git branch --merged | grep -v &#39;\*\|master\|develop\|release-&#39; | xargs -n 1 git branch -d
b = !git for-each-ref --sort=&#39;-authordate&#39; --format=&#39;%(authordate)%09%(objectname:short)%09%(refname)&#39; refs/heads | sed -e &#39;s-refs/heads/--&#39;
trim = !git reflog expire --expire=now --all &amp;amp;&amp;amp; git gc --prune=now
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I use &lt;code&gt;audit&lt;/code&gt; and &lt;code&gt;clean-audit&lt;/code&gt; the most frequently.  &lt;code&gt;audit&lt;/code&gt; simply lists my
local branches that have already been merged (except for &lt;code&gt;master&lt;/code&gt;, &lt;code&gt;develop&lt;/code&gt;,
and the &lt;code&gt;release&lt;/code&gt; branches) and hence are not needed anymore. &lt;code&gt;clean-audit&lt;/code&gt;
simply extends that command to delete the listed branches.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;b&lt;/code&gt; alias prints a summary of all local branches, it looks likes this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Fri Mar 17 16:19:24 2017 -0600	4d2a351	master
Fri Mar 17 15:08:31 2017 -0600	d9ce23e	release-17.12.01
Fri Mar 17 13:21:34 2017 -0600	a5d5f73	develop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I use &lt;code&gt;trim&lt;/code&gt; pretty sparingly. It simply cleans up old branch pointers that are
not being used as of &amp;ldquo;now&amp;rdquo;.  This can be useful to reclaim some space after you
do &lt;code&gt;clean-audit&lt;/code&gt;.  I only recommend this command if you have OCD.&lt;/p&gt;

&lt;h2 id=&#34;historical-logging&#34;&gt;Historical Logging&lt;/h2&gt;

&lt;p&gt;The following commands will print your &lt;code&gt;git log&lt;/code&gt; in fun, potentially
informative, ways:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;graph = log --graph --oneline --decorate --all
l = log --pretty=format:%C(yellow)%h\ %ad%Cred%d\ %Creset%s%Cblue\ [%cn] --decorate --date=short
ll = log --pretty=format:%C(yellow)%h%Cred%d\ %Creset%s%Cblue\ [%cn] --decorate --numstat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assuming that you and your team are writing good summary lines in your commit
messages, these commands can be used to quickly find when a certain commit
happened.  I don&amp;rsquo;t use these frequently, but they have been useful when trying
to find when something happened in the repo.  &lt;code&gt;git l&lt;/code&gt; is great a really short
summary of the history, e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;af1f3ec 2017-03-05 (HEAD -&amp;gt; source-hugo, origin/source-hugo) Site rebuild Sun Mar  5 13:53:22 MST 2017 [Lucas Roesler]
ddfdd9d 2017-03-05 Post new spring hefe beer post [Lucas Roesler]
e5bd906 2017-02-25 Site rebuild Sat Feb 25 13:33:12 MST 2017 [Lucas Roesler]
bd21f27 2017-02-25 Add a reading list page [Lucas Roesler]
dad0fbb 2017-02-18 Site rebuild Sat Feb 18 20:20:50 MST 2017 [Lucas Roesler]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you need a little more detail, &lt;code&gt;git ll&lt;/code&gt; will show you the change stats as
well as the summary that you get in &lt;code&gt;git l&lt;/code&gt;, e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;af1f3ec (HEAD -&amp;gt; source-hugo, origin/source-hugo) Site rebuild Sun Mar  5 13:53:22 MST 2017 [Lucas Roesler]
21      1       public/2017/01/hello/index.html
21      1       public/2017/01/my-management-philosophy/index.html
21      1       public/2017/01/spicy-winter-porter/index.html
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;commit-helpers&#34;&gt;Commit helpers&lt;/h2&gt;

&lt;p&gt;I only have one alias related to commits &lt;code&gt;fixup&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fixup=!git commit --amend
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will take your staged changes and immediately squash them into the
previous commit.  This is great for fixing small typos and simply reduces the
amount of time I need to spend in &lt;code&gt;rebase&lt;/code&gt;. This is by far my most frequently
used alias.&lt;/p&gt;

&lt;h2 id=&#34;adding-aliases&#34;&gt;Adding aliases&lt;/h2&gt;

&lt;p&gt;Adding these aliases to your system is pretty simple. In your &lt;code&gt;~/.gitconfig&lt;/code&gt;
file, add or update the &lt;code&gt;[alias]&lt;/code&gt; section with the snippets I shared above. My
config file looks like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[alias]
    fixup=!git commit --amend

    # cleanup old branches
    audit = &amp;quot;!git branch --merged | grep -v &#39;\\*\\|master\\|develop\\|release-&#39;&amp;quot;
    clean-audit = &amp;quot;!git branch --merged | grep -v &#39;\\*\\|master\\|develop\\|release-&#39; | xargs -n 1 git branch -d&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;

&lt;p&gt;Git is a powerful tool, one of my favorites. I like a semantic git logs, so I
use rebase. You don&amp;rsquo;t have to do this. But, you better write good commit
messages :)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A spring Hefe</title>
      <link>http://lucasroesler.com/2017/03/a-spring-hefe/</link>
      <pubDate>Sun, 05 Mar 2017 00:00:00 -0700</pubDate>
      
      <guid>http://lucasroesler.com/2017/03/a-spring-hefe/</guid>
      <description>&lt;p&gt;A traditional Bavarian Hefeweizen: medium body, cloudy, malty, and spicy,
with a smooth mouth-feel and dense, whipped-cream head.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;recipe&#34;&gt;Recipe&lt;/h3&gt;

&lt;p&gt;This is the full grain recipe for a 5 gallon batch&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Grains:
- 5.5 lbs Weyermann Pale Wheat malt
- 4 lbs German Pilsner malt&lt;/p&gt;

&lt;p&gt;Hops:
- 1 oz German Tettnang for 60 min&lt;/p&gt;

&lt;p&gt;Yeast:
- Fermentis Safbrew WB-06 Dry Yeast&lt;/p&gt;

&lt;p&gt;Target O.G: 1.049&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I converted this to a partial mash using the following tweak&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Grains:
- 5.5 lbs Weyermann Pale Wheat malt
- 0.5 lbs 6 Row
- 3 lbs lbs dry malt extract&lt;/p&gt;

&lt;p&gt;Hops:
- 1 oz German Tettnang for 60 min&lt;/p&gt;

&lt;p&gt;Yeast:
- Fermentis Safbrew WB-06 Dry Yeast&lt;/p&gt;

&lt;p&gt;Target O.G: 1.049&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At the end of the brew I recorded an original gravity of 1.045.&lt;/p&gt;

&lt;h3 id=&#34;the-result&#34;&gt;The Result&lt;/h3&gt;

&lt;p&gt;Ferment for two weeks and bottle condition for another two weeks and then
enjoy.  I recorded a final gravity of about 1.020 before bottling. Today is the
first tasting day, observer the first pour&lt;/p&gt;




&lt;div class=&#34;figure &#34; &gt;
  
    &lt;img class=&#34;fig-img&#34; src=&#34;https://lh3.googleusercontent.com/M4iHvH3Yocb2NOzQSDt9PZVm4qpSChNnFGmEELqv2b-ya3r_3W19XuEgwhD1el2lWktcUAGMMBvR4N4iIUFuXng5wdvZbxzEj5As6fx7U7a4leNl71C5LwDxmyukWjFnCpOnY6me47QCuBua7AHAY5HHZK2MVlwYnQv5pea27ZIvI4M0ijUZBc8blBHE_ITPGeyPHD9zKHx4FzTbbuxkr1Cf7074C7fKCOGIgdjQWTbHmrro4t5YpllyHIqIfKKnEvOni-rHopSsUc-5sy7837myS-5lvoV_UaFKlJkw3KCAEyrbK-1bsKOHt9_vEjDfa0MkIiV1IgF6ZSUW8brRUBbwxy2Y04djJxABqzsPcqESAQIkQzBjS9F4UBPmyQg0d0X7J9fT_PEblHQe-YQqhOTdoIqTx5lSO90Gp6F5QXVUF3qPv14GiBdhAEh6wEof6ORCSiNTcQM0BETPmvIOLmu6KJDXsQPe9czl1-I5eX3atDA2QU5UBHhLUbvyt6epOVwwXpAVEK4CekcR-bHNNWIm1bqdq6t-JWkhSfG1ZKe7v5KqdGlVrVfEcZt4SRVEYQEDOuKc0n8v3mqSkkNxSJhKtHKbtuQa_8UnE_8t0_qRD3W2cHTJUbOfloAEpgggPy0Tj6ERJp8lwMkJZrq4mdLuw3cy2ARm92wnSs7tUw=w1750-h1552-no&#34;  alt=&#34;First Taste&#34;&gt;
  
   
    &lt;span class=&#34;caption&#34;&gt;First Taste&lt;/span&gt;
  
&lt;/div&gt;


&lt;p&gt;As desired, a nice traditional Hefeweizen: cloudy appearance with a fruity
aroma. This beer came out with a nice smooth, sweet, and light flavor.  It will
be a perfect spring beer, which is exactly what I was aiming for.&lt;/p&gt;

&lt;p&gt;The only concern I have with this beer is that my sugar conversion was not very
efficient. As a result, the bottle conditioning has resulted in a &amp;ldquo;well
carbonated&amp;rdquo; beer. Word of warning if I give you one of these, please open over
a sink because it will immediately overflow the bottle!&lt;/p&gt;

&lt;p&gt;Additionally, the recipe specifically does not include a secondary fermentation
stage and this has resulted in more sediment than I really like in the bottles.
The reason to skip the secondary is to help maintain the cloudy body of
the beer.  However, if I were to brew this recipe again, I would definitely do
a secondary stage.  The secondary stage would most likely help with the
conversion issue as well.&lt;/p&gt;

&lt;p&gt;Either way I am still going to enjoy this batch.  I have included a few more
pictures of my brewing process below, enjoy!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reading list</title>
      <link>http://lucasroesler.com/reading-list/</link>
      <pubDate>Sat, 25 Feb 2017 00:00:00 -0700</pubDate>
      
      <guid>http://lucasroesler.com/reading-list/</guid>
      <description>

&lt;h1 id=&#34;my-reading-list&#34;&gt;My Reading List&lt;/h1&gt;

&lt;p&gt;A simple list of books that I am actively reading or have read recently.&lt;br /&gt;
(Idea shamelessly stolen from &lt;a href=&#34;https://www.susanjfowler.com/reading-list/&#34;&gt;Susan J. Fowler&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&#34;currently-reading&#34;&gt;Currently Reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/2312-Kim-Stanley-Robinson-ebook/dp/B004RD8544/&#34;&gt;2312 by Kim Stanley Robinson&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;coming-soon&#34;&gt;Coming Soon&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/B0082TAAMO/&#34;&gt;The Illiad trans. by Alexander Pope&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2017&#34;&gt;2017&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/gp/product/B01CESQNQK/&#34;&gt;13.8: The Quest to Find the True Age of the Universe and the Theory of
Everything by John Gibbin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Zero downtime deploys: A tale of Django migrations</title>
      <link>http://lucasroesler.com/2017/02/zero-downtime-deploys-a-tale-of-django-migrations/</link>
      <pubDate>Mon, 20 Feb 2017 00:00:00 -0700</pubDate>
      
      <guid>http://lucasroesler.com/2017/02/zero-downtime-deploys-a-tale-of-django-migrations/</guid>
      <description>&lt;p&gt;At Teem, we aim for zero down-time deploys; so, one of the most
important things we must validate is that things will not break mid-deploy!&lt;/p&gt;

&lt;p&gt;The most sensitive step of the deploy process is the changes to our database.
Prior to the automation I am about to describe, validation of the database
migrations required specialized knowledge about Postgres, the changes to the
application model, load on the database for that model, and a bit of general
experience. This obviously slows down reviews and subsequently deploys. Worse,
it was simply too easy to miss problem migrations when depending on only peer
reviews. To make our lives easier we created a series of validation checks to
ensure that each database migration will be backwards compatible.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-what&#34;&gt;The what&lt;/h2&gt;

&lt;p&gt;The checks I am going to describe are simply a sequence of regex
that we run on the migrations in the changelog. The process looks, roughly,
like this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Using git, generate a list of new migrations in this release,&lt;/li&gt;
&lt;li&gt;Using Django&amp;rsquo;s &lt;code&gt;sqlmigrate&lt;/code&gt; manage command, generate the SQL for each
migration,&lt;/li&gt;
&lt;li&gt;Run a sequence of regex on each SQL command,&lt;/li&gt;
&lt;li&gt;Report the issues,&lt;/li&gt;
&lt;li&gt;Profit!&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We do this in a python script we internally call &lt;code&gt;octoeb&lt;/code&gt; which uses
&lt;a href=&#34;http://click.pocoo.org/5/&#34;&gt;Click&lt;/a&gt; to create a commandline
interface.  So, I can get a changelog along with an audit of the migrations
in my current branch using:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ocotoeb changelog
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I won&amp;rsquo;t describe the specific python code, instead I will give you equivalent bash commands
that you can run in your CLI and a simple description of the regex that we
are using. This will give you all the pieces you need to build a similar script
in your favorite language.&lt;/p&gt;

&lt;h2 id=&#34;the-why&#34;&gt;The why&lt;/h2&gt;

&lt;p&gt;The basic goal is to ensure that any applied migrations are backwards
compatible with the model definitions in the currently deployed release. This
is a requirement because our current deployment process looks like:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;pull the new release code to a single server,&lt;/li&gt;
&lt;li&gt;run the migrations,&lt;/li&gt;
&lt;li&gt;restart the application,&lt;/li&gt;
&lt;li&gt;check the application status,&lt;/li&gt;
&lt;li&gt;slowly roll the code to the rest of the servers.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As a result, during a deploy we have a mix of old model definitions and new
model definitions running simultaneously.  This means that the database must
except both the old and the new for a short period of time and that any change we make
to the database should not lock up an entire table.&lt;/p&gt;

&lt;p&gt;Probably the most common change we often want to make is simply adding a new
column to an existing model.  This can present several issues.  First, your new
column should not set a default.  In postgres, adding a column with a default will
lock the table while it rewrites the existing rows with the default.  This can
easily be avoided by adding the column first without the default, then adding
the default, followed by a future backfill on the existing rows.  This will
create the column and all future rows will have the default.&lt;/p&gt;

&lt;p&gt;Implicit in the above recommendation is that all new columns must be nullable.
You can not add a column without a default unless you allow null. Additionally,
while the old models are running against the new table definitions, the app
will set a value for that column, so it must either have a default or allow
null otherwise Postgres will throw an error.&lt;/p&gt;

&lt;p&gt;Finally, the other change that we need to watch for is removing columns. This
is a multi-step process. If you drop a column while the old models are still
active you will get two possible errors (1) when Django tries to select on
that column that no longer exists (which it will because it always explicitly
names the columns selected) or (2) attempting to insert data to a column that
doesn&amp;rsquo;t exist anymore. To actually handle this type of model change you must
deploy the model change prior to running the migration.  In our process, that
means you must commit the model change in a release separate from the database
migration.&lt;/p&gt;

&lt;p&gt;There are certainly other cases to consider, but we have found these 3 cases to
cover the vast majority of our migration concerns. Having put these checks into
place, we rarely have any issues with database migrations during deploy.&lt;/p&gt;

&lt;h2 id=&#34;the-how&#34;&gt;The how&lt;/h2&gt;

&lt;h3 id=&#34;getting-your-list-of-migrations&#34;&gt;Getting your list of migrations&lt;/h3&gt;

&lt;p&gt;To find the new migrations you can run the following command&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git log --name-status master.. | grep -e  &amp;quot;^[MA].*migrations.*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Breaking this down, &lt;code&gt;git log --name-status master..&lt;/code&gt; will print a log of the
commits and the file changes in each commit between &lt;code&gt;master&lt;/code&gt; and the current
&lt;code&gt;HEAD&lt;/code&gt;.  The &lt;code&gt;grep&lt;/code&gt; returns only those lines that start with &lt;code&gt;A&lt;/code&gt; or &lt;code&gt;M&lt;/code&gt; and
also contains the work &lt;code&gt;migrations&lt;/code&gt;.  These are all of the new or modified
migration files.  It will return something like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A	apps/accounts/migrations/0019_auto_20170126_1830.py
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;getting-your-sql&#34;&gt;Getting your SQL&lt;/h3&gt;

&lt;p&gt;Once you have the list of migration files that you need to check, we need to
get the actual SQL that is going to be run by Django.  Fortunately, Django
provides a simple command to get this SQL,
&lt;a href=&#34;https://docs.djangoproject.com/en/1.10/ref/django-admin/#sqlmigrate&#34;&gt;&lt;code&gt;sqlmigrate&lt;/code&gt;&lt;/a&gt;.
For example,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;django-admin sqlmigrate account 0002
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will print the sql for the second migration in the &lt;code&gt;accounts&lt;/code&gt; app. In the
pervious section the ouput contains all of the information that we need.
Specifically, with a command like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git log --name-status master.. | grep -e  &amp;quot;^[AM].*migrations.*&amp;quot; | cut -d / -f 2,4 | cut -d . -f 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;we would get back exactly the list of apps and the migration name for each
migration that we need to check&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;accounts/0017_auto_20170126_1342
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This still isn&amp;rsquo;t quite what we need.  At the end of the day the following
command will generate the SQL for you&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git log --name-status master.. | grep -e  &amp;quot;^[AM].*migrations.*&amp;quot; | cut -d / -f 2,4 | cut -d . -f 1 | awk -F&amp;quot;/&amp;quot; &#39;{ print $1,$2}&#39; | xargs -t -L 1 django-admin sqlmigrate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are using python for our scripting, so my script is actually a bit
different, using the regex &lt;code&gt;apps/((.*)/migrations/(\d+[0-9a-z_]*))\.py&lt;/code&gt; and a
combination of a for loop and subprocess to generate the SQL.&lt;/p&gt;

&lt;h3 id=&#34;regex-magic&#34;&gt;Regex magic&lt;/h3&gt;

&lt;p&gt;Now that we have the actual SQL that needs to be tested, it is simply a matter
of running a few regex tests. We have 3 core tests that we run:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;check_for_not_null&lt;/code&gt; which we test using &lt;code&gt;/NOT NULL/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;check_for_dropped_columns&lt;/code&gt; which we test using &lt;code&gt;/DROP COLUMN/&lt;/code&gt;,
and&lt;/li&gt;
&lt;li&gt;&lt;code&gt;check_for_add_with_default&lt;/code&gt; which we test using &lt;code&gt;/ADD COLUMN .* DEFAULT/&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For each migration, we test those 3 regex and alert if they have any matches.
As I mentioned earlier, there are certainly other cases that could be
considered. Let me know if there are some additional checks I should add.
Since we have implemented these checkes, I can&amp;rsquo;t remember the last time we had
a migration issue during a deploy so they seem to cover most of the use cases
we run into.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Postgres Joins and Django Querysets</title>
      <link>http://lucasroesler.com/2017/02/postgres-joins-and-django-querysets/</link>
      <pubDate>Mon, 06 Feb 2017 20:00:00 +0000</pubDate>
      
      <guid>http://lucasroesler.com/2017/02/postgres-joins-and-django-querysets/</guid>
      <description>&lt;p&gt;How do we build a fast API against database models with foreign keys and many-
to-many relationships?  If you do nothing you get what I call the &amp;ldquo;waterfall of
doom&amp;rdquo;. At some point in the past someone told me or I read that &amp;ldquo;joins are
effectively free in Postgres&amp;rdquo;.  While this might be somewhat true when you are
writing all of the SQL and can control every part of your query; I have recently
found that when the database gets big enough and you are using the Django ORM,
joins aren&amp;rsquo;t free and less can be more!&lt;/p&gt;

&lt;p&gt;Warning, I am not a DBA and mileage may vary.&lt;/p&gt;

&lt;!-- more /--&gt;

&lt;p&gt;At &lt;a href=&#34;https://teem.com&#34;&gt;Teem&lt;/a&gt; we deal with a lot of calendar data.  For various
reasons this means we have database tables that looks something like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+----------------------+    +----------------------+
|Calendar              |    |Event                 |
|========              |    |=====                 |
|- id                  |    |- id                  |
|- source              |    |- organization_id     |
|- organization_id     |    |- calendar_id         |
|                      |    |- organizer_id        |
+----------------------+    |- title               |
                            |- start_at            |
                            |- end_at              |
                            +----------------------+
+----------------------+    +----------------------+
|Participant           |    |Organizer             |
|===========           |    |=========             |
|- id                  |    |- id                  |
|- organization_id     |    |- organization_id     |
|- event_id            |    |- event_id            |
|- email               |    |- name                |
|- name                |    |- email               |
+----------------------+    +----------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;em&gt;Note this is not how it is actually setup in production.&lt;/em&gt;)&lt;/p&gt;

&lt;p&gt;Now, you can be happy or upset with the design for various reasons
but my biggest issue is how Django queries these tables for our API.  The
simplest most direct way to serialize an Event including its calendar,
organizer, and the participants cause what I call the &amp;ldquo;waterfall of doom&amp;rdquo;,
a.k.a. the N+1 problem. This topic is covered in many places throughout the
internet, for example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://secure.phabricator.com/book/phabcontrib/article/n_plus_one/&#34;&gt;Performance: N+1 Query Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://stackoverflow.com/questions/97197/what-is-the-n1-selects-problem&#34;&gt;What is the n+1 selects problem?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;so I won&amp;rsquo;t focus on it here; but basically, every request for an Event results
in 4 more requests (&lt;em&gt;the waterfall&lt;/em&gt;) for Organization, Calendar, Organizer, and
the Participants respectively.  Even worse, if I request a list of Events the
simplest code for the API will do 4 database queries for each Event in the list
(&lt;em&gt;the waterfall of doom&lt;/em&gt;). For a single event this isn&amp;rsquo;t noticeable, but if I
want to serialize all events in a calendar, it is a big performance problem.&lt;/p&gt;

&lt;p&gt;We use &lt;a href=&#34;http://www.django-rest-framework.org/&#34;&gt;Django Rest Framework&lt;/a&gt;, so the
simple (and bad) Event serialization described above looks something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class EventSerializer(ModelSerializer):
    organizer = OrganizerSerializer(read_only=True)
    calendar =  CalendarSerializer(read_only=True)
    organization = OrganizationSerializer(read_only=True)
    participants = ParticipantSerializer(
        source=&#39;participant_set&#39;, many=True, read_only=True)

    class Meta:
        fields = (
            &#39;id&#39;, &#39;start_at&#39;, &#39;end_at&#39;, &#39;title&#39;,
            &#39;organizer&#39;, &#39;calendar&#39;, &#39;organization&#39;, &#39;participants&#39;,
        )

class EventViewSet(ReadOnlyModelViewSet):
    queryset = Event.objects.all()
    serializer_class = EventSerializer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is worth noting that this is clearly not how our production API is currently
designed; but, it demonstrates the core performance issue. Fortunately,
&lt;a href=&#34;https://docs.djangoproject.com/en/1.10/topics/db/optimization/#retrieve-everything-at-once-if-you-know-you-will-need-it&#34;&gt;Django provides a couple tools&lt;/a&gt;
out of the box to help us solve this performance issue: &lt;code&gt;prefetch_related&lt;/code&gt;
and  &lt;code&gt;select_related&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If you are familiar with Django, then this is not news to you.  Given the setup
above you would likely jump on &lt;code&gt;select_related&lt;/code&gt; and call it a day, e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class EventViewSet(ReadOnlyModelViewSet):
    queryset = Event.objects.select_related(
        &#39;organizer&#39;, &#39;calendar&#39;, &#39;participant_set&#39;).all()
    serializer_class = EventSerializer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In fact, for a short time, this optimization worked for us; but a problem pops
up when the database starts getting big.  The above ViewSet will generate SQL
like this&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT COUNT(*) FROM (
    SELECT DISTINCT ON (
        e.start_at, e.end_at, e.title
        )
        e.*,
        o.*
    FROM event e
        LEFT OUTER JOIN participant p
            ON ( e.id = p.event_id )
        LEFT OUTER JOIN organizer o
            ON ( e.id = o.event_id )
    WHERE (
        e.calendar_id =  5051
        AND e.start_at &amp;lt;= &#39;2016-12-02 00:00:00+00:00&#39;
        AND e.end_at &amp;gt;= &#39;2016-12-01 00:00:00+00:00&#39;
        AND (
            UPPER(p.email::text) = UPPER(&#39;name@example.com&#39;)
            OR UPPER(o.email::text) = UPPER(&#39;name@example.com&#39;)
        )
    )
    ORDER BY
        e.start_at ASC,
        e.end_at ASC,
        e.title ASC,
) sub;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which looks good, but here is the problem&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh3.googleusercontent.com/42eujc1S4_syWt2a64akZ28YxvBPofo2vHeJLWE_OwwSyruc_xLZvoe2RPIsRHHM_hTqHgjT6tH1-v9U76juQ2Ik7qInTADCbMpqFJC-hIswhJt8u36Y4dXdla9ffOy1GkI2OFxO_OXsSlDpjJJEUJs3cew54TEiLOT7zupFmzyA2LVGf8aYExjzKpYIQLdctzPPk59ecdNlhtscFZNl6Q47vHKyyq04CYOaHHop-KrOJMVAsorJbb8EYeVnrcanmM6Iowy5hkfRa2NuUMEvzOnd3hoZPxSVxNRTZukULPTsgCmTw5-cbUQi_9T3zrIRpypqEzjH1WaCaBeTtzBJlncNEC6MYM1GFP7e68qBMZpuAIzO-i4i43dTY5n3IfpY--ESYXtOp6xhKEWvOIDUtYGxXNow7HOWuluiOC0rWffxdDUWgDgv_CAAmVBCIWMvUXPOinz2N18V28-SeMsLG7Lsi6CiMu4ZfJGA44m6vY1CAi_3pQTXdB7xr1YU05Bzu4qyJiV0hRThIrC3GIj4nPo0wxI1PYneHY-AnAXmxVpMerQkKdtYpglv3DuJQraoxJg9Iu_nxoQO73fi6C7ZXisrVj-wCZE6_HsRYlsm5Yp_kH365gsX=w1440-h476-no&#34; alt=&#34;Example Performance with select_related&#34; /&gt;&lt;/p&gt;

&lt;p&gt;21 seconds querying the events table in our real life production database! Why
oh why is this happening?  A quick &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt; shows that Postgres is
doing sequential scan on &lt;code&gt;participant&lt;/code&gt; and &lt;code&gt;organizer&lt;/code&gt;.  Now, I am not a DBA so
I can&amp;rsquo;t fully explain why this is happening, but I do have some ideas about how
to avoid the scan.  Here is the fastest query I could make in SQL&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT COUNT(*) FROM (
    SELECT DISTINCT ON (
        e.start, e.end, e.title,
        )
        e.*,
        o.*
    FROM event e
        LEFT OUTER JOIN (
            SELECT * FROM participant
            WHERE
                participant.organization_id = 9776
                AND UPPER(participant.email::text) = UPPER(&#39;name@example.com&#39;)
        )
        p ON ( e.id = p.event_id )
        LEFT OUTER JOIN (
            SELECT * FROM organizer
            WHERE UPPER(organizer.email::text) = UPPER(&#39;name@example.com&#39;)
        ) o ON ( e.id = o.event_id )
    WHERE (
        e.organization_id =  9776
        AND e.start_at &amp;lt;= &#39;2016-12-02 00:00:00+00:00&#39;
        AND e.end_at &amp;gt;= &#39;2016-12-01 00:00:00+00:00&#39;
        AND (p.id IS NOT NULL OR o.id IS NOT NULL) -- User filter applied in subselect joins
    )
    ORDER BY
        e.start_at ASC,
        e.end_at ASC,
        e.title ASC
) sub;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This query is fast in production, but &amp;hellip; it can not be produced using the
Django ORM. Here, I explicitly made subqueries on indexed columns to speed it
up. In a future post, I promise to discuss how and when we use raw SQL so speed
up some of our requests. But, for the general CRUD API endpoint, I want to use
the ORM so that I can leverage the great filter framework provided by Django
Rest Framework. After a lot of tinkering, the best ORM compatible query I could
design is this&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT COUNT(*) FROM (
    SELECT DISTINCT ON (
        e.start, e.end, e.title
        )
        e.*,
        o.*
    FROM event e
        LEFT OUTER JOIN participant p
            ON ( e.id = p.event_id )
        LEFT OUTER JOIN organizer o
            ON ( e.id = o.event_id )
    WHERE (
        e.organization_id =  9776
        AND e.start_at &amp;lt;= &#39;2016-12-02 00:00:00+00:00&#39;
        AND e.end_at &amp;gt;= &#39;2016-12-01 00:00:00+00:00&#39;
        AND (
            UPPER(p.email::text) = UPPER(&#39;name@example.com&#39;)
            OR UPPER(o.email::text) = UPPER(&#39;name@example.com&#39;)
        )
        AND (p.organization_id = 9776 OR p.organization_id IS NULL)
    )
    ORDER BY
        e.start_at ASC,
        e.end_at ASC,
        e.title ASC
) sub;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For specific API queries, we actually using a similar query in production. But,
I couldn&amp;rsquo;t find a good general solution until I realized that trying to do
everything at once might actually be too much to ask for, especially since the
API enforces relatively small pages. While reading through the documentation to
hunt down another bug, I &lt;a href=&#34;https://docs.djangoproject.com/en/1.10/ref/models/querysets/#prefetch-related&#34;&gt;re-read the docs&lt;/a&gt;
son &lt;code&gt;prefetch_related&lt;/code&gt; and it occurred to me that I could guarantee
exactly 4 fast queries to the db on every API call instead of one sporadically
slow query.  With the following small change to our viewset definition, our
slowest API call is an order of magnitude faster than the previous call with the
&lt;code&gt;select_related&lt;/code&gt; (although there is room for improvement)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh3.googleusercontent.com/pUhp4eFa0T-hdtkHBUiowhLMhz9VTbWjt7L7iorDjvGpvybFl32Y-hK70ndpgmiCm33cHhsKqFSaj99IERwt28YHe-Ndb9jutVHWHCoVq0hjiCnws7HhgqGh5z1v40yZbihCgxDTf8Wf-dAXwyAYQ0RttclPPNIE4sLMUioLnkosHWYJ_if9VVjJ6xOPZACDGC70MijYqOG2TfYyKNBGmExl6mFf-F2v-vkNsXHFQzs9Wm12yM0TJ7Hrx7LOrHIOcVjb3OxBveoedc_qXoG89rTb3h9xvRRDigG0bEFcEYVRi3WjNsXt3gpuXb05tOepcgpLAHG8Nfpjx0cW0axwInwVPdrxLcfEbH6SnnnFNpTQQIX3UtEDV3z0AKvpFQwfvz8lfdc2Jr3FCXJqG0AtxXV1PwbWMZ4wudtcgLogUYkxXsfzTTRlDO5p8bPZZQSdfCDCrJdp_3lj1FUK7aNZsTVN-7-lVKdCQbYXEOit01zA_Jrv3fWM5znx1OPe_kMNWQqnpOk6uRT97zAi2Boopu4fnyoLn-wDfuiw10wpfaQEFIC910tSOeD1RBn9AF5lOlbop_vYrTU5Z5VBN3izI-ug8ucJKk6YgIb9bv2epzGTDUaehdIheMYEWtoAnmcSFE3XEFR--hy1m_w-1TZAIS4ex_A0O-cQ5DgaFzKTfg=w2286-h620-no&#34; alt=&#34;Performance with prefetch_related&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In fact, the careful observer will notice that the called components in this
trace are a bit different.  Well, the &lt;code&gt;prefetch_related&lt;/code&gt; was so successful,
that the same exact query no longer qualifies for being traced in New Relic and
the average dropped by half!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://lh3.googleusercontent.com/IGNUFurt9JEPG5c_zHAO8RkML0joObxq66RPZ7ga3xrXYGpnKiNjUPMDAsGCGuEZ4nyMJz7crE5a5UuBQuMFSTl6biLTsahB6MPbbCLehVaBGhaJTQvrwvWao0049ksDScEb6l5KgqPr8kXZ75L1k3V1B2QGpzUTeV0jN3d2SWGtuHFrW6K2wNdnjGifnBP5bXcB_3MoAvj3ZAXmvmI08_o_n_UjSN0fSMAupq2tR013pB4HGYr1HXIN9-UZRc9oqjMqtu2rslGQi0FTxrOHY5xfn6lX-0Hzy8d0qKSkhrkW8GYkk0rZwRcoQonrivtCOMeXkFB2d5l45FZlW0oM2Yo0W9Zc_jFKeRnLSyX0cdbutBCoR1Q4KFxRKz0dFrPJFCvUA4gngJ_IYdkriL6uAIq1p3lHPze_1XI2reHp2qM689-ggmppmwrlyT6QVVMy5jA6xKG7hklVkmtgsm-aj8nw5tD3OkCbJLRlAJJabIxusEKHTTI5rDtXKaqkBAidWmAF1PMuEuj2wcNQvLCN93Y2Sy_zL-aY4JDpRFbmbYh2PfJarmHhibCUF3pWK79kI_uqLwmPb1a6g1UkuFQb1zA2FmXaoKD_T8wUBOUWfQ6NhKg6gCV_SYngrtMcvI3-nDmcvIALEn7xOaM32TGOAPx5igkG7QDkM2-dKHKjNA=w1260-h298-no&#34; alt=&#34;average reservations api call&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I would like to caution that I believe this works so well in this case because we
limit the API page size, so, the data and query sizes in the related queries are
relatively small per request. If you need to load a lot of data at once, I can
foresee this solution being much worse than &lt;code&gt;select_related&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;TL;DR: Monitor and analyze your production queries and &lt;code&gt;prefetch_related&lt;/code&gt; can
be a great solution if you can keep the number of queries and the page size
small.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My Management Philosophy</title>
      <link>http://lucasroesler.com/2017/01/my-management-philosophy/</link>
      <pubDate>Sun, 29 Jan 2017 20:00:00 -0700</pubDate>
      
      <guid>http://lucasroesler.com/2017/01/my-management-philosophy/</guid>
      <description>&lt;p&gt;The other day I was having lunch with a friend when he asked what resources I
use to learn about management and tech leadership in general. I will share
some recommendations at the end, but my answer to him got me thinking about
my philosophy around management and how to be good at it, which is what I really
want to share here.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR: be a multiplier for your team and reduce friction.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;how-to-get-better-at-management&#34;&gt;How to get better at management&lt;/h2&gt;

&lt;p&gt;When I started answering my friend, I of course had some sort of a list and
made a few suggestions, but immediately followed with this (or something
roughly paraphrased as such):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I don&amp;rsquo;t think reading these is particularly that important, instead
find stuff that makes you think about how and what it means to be a leader
and to manage a team.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Obviously reading good content with solid concrete suggestions is a good thing,
but, the core of what I am trying to convey and my philosophy
about how to succeed in management (especially in tech) is this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It is a real job, be intentional about it, care about it, and don&amp;rsquo;t
cut corners.  Your are here to help other people get &lt;strong&gt;their&lt;/strong&gt; jobs done.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Often we take senior developers and slowly (or abruptly) move them in leadership
roles that they don&amp;rsquo;t want.  If I had to choose between a very good senior dev
that doesn&amp;rsquo;t want the job and a mid-to-senior dev that does, I would take the
latter because ultimately the job is about helping other people and if you don&amp;rsquo;t
care about it, then you aren&amp;rsquo;t going to be much help.  The job is hard work
and taking shortcuts or ignoring it will create minor issues out of nothing
and turn minor issues into major issues.&lt;/p&gt;

&lt;h2 id=&#34;what-is-management&#34;&gt;What is management&lt;/h2&gt;

&lt;p&gt;At &lt;a href=&#34;https://teem.com&#34;&gt;Teem&lt;/a&gt; I have the dubious role of lead cat herder, a.k.a.
director of engineering. I am not directly managing a group of engineers on a
specific project or in a specific skill group, instead I have to guide leaders
for those in how to organize and manage their teams. My one guiding principle
that I give to them (and myself) is that&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;the management/leadership role is a service role with one primary objective:
&lt;strong&gt;be a multiplier for your team&lt;/strong&gt;. At the end of the day you are a success if
&lt;strong&gt;you reduce friction&lt;/strong&gt; so that your team is able to get more done because of
you.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Successful managers make other people better at their jobs, &amp;ldquo;multiplying&amp;rdquo; their
productivity.  This can be getting more work done, getting the right work done,
or simply producing better, more stable end results. But it is important not to
focus only on being a &amp;ldquo;multiplier&amp;rdquo;. As a manager, it is the pair of
&lt;strong&gt;be a multiplier for your team&lt;/strong&gt; and &lt;strong&gt;reduce friction&lt;/strong&gt; combined that produces
the real magic. You can have the appearance of a multiplier by being a bottleneck
or inserting yourself as a dependency even where you don&amp;rsquo;t need to be.
&lt;em&gt;Look at all this work they couldn&amp;rsquo;t have done without me!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Beyond &lt;strong&gt;be a multiplier&lt;/strong&gt; and &lt;strong&gt;reduce friction&lt;/strong&gt; my only other
commandment is that you must hold regular one-on-ones! To reduce the friction
for your team you have to know what they are doing, how they are doing it, and
why they are frustrated.  The fastest, easiest way to understand what
is happening is through frequent and private time to talk. In the future, I will
go through my one-on-one process.&lt;/p&gt;

&lt;h2 id=&#34;my-resource-list&#34;&gt;My Resource List&lt;/h2&gt;

&lt;p&gt;Without further ado, here are a couple suggestions for learning about leadership:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://randsinrepose.com/&#34;&gt;Rands in Repose&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;The blog has simply great content on leading tech teams fueled by direct
experience.&lt;/li&gt;
&lt;li&gt;His book &lt;a href=&#34;https://www.amazon.com/Managing-Humans-Humorous-Software-Engineering/dp/1484221575/&#34;&gt;Managing Humans&lt;/a&gt;
is a must read that provides a ton of food for thought with great examples
and advice.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manager-tools.com/&#34;&gt;Manager Tools&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Great podcast that focuses on the gritty details of management.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/PicardTips&#34;&gt;@PicardTips&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;This is mostly a fun suggestion. It almost always makes me stop
for a moment and think, &amp;ldquo;what is good leadership?&amp;rdquo;  Which is great to get
in tiny frequent doses in my Twitter timeline.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here are some other books (suggested by many people) that I think are worth
reading because they will make you think:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Hard-Thing-About-Things-Building/dp/0062273205/&#34;&gt;The Hard Thing About Hard Things&lt;/a&gt; by Ben Horowitz&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/How-Google-Works-Eric-Schmidt/dp/1455582344/&#34;&gt;How Google Works&lt;/a&gt; by Eric Schmidt&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.com/Zero-One-Notes-Startups-Future/dp/0804139296/&#34;&gt;Zero to One&lt;/a&gt; by Peter Thiel&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I split these out from the previous list because while they are good reads, I
don&amp;rsquo;t find myself revisiting them frequently.  This may have more to do with the
format, books versus blogs or podcasts.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Spicy Winter Porter</title>
      <link>http://lucasroesler.com/2017/01/spicy-winter-porter/</link>
      <pubDate>Sun, 15 Jan 2017 13:48:19 -0700</pubDate>
      
      <guid>http://lucasroesler.com/2017/01/spicy-winter-porter/</guid>
      <description>&lt;p&gt;I just finished my winter beer.  I usually do one dark spicy beer for the winter
season. Last year was the &amp;ldquo;Better Not Pout Stout&amp;rdquo;, this year is the less
excitingly named &amp;ldquo;Spicy Winter Porter&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-recipe&#34;&gt;The recipe&lt;/h3&gt;

&lt;p&gt;This is a partial mash recipe for a 5 gallon batch.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Grains:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;5 lbs Pale Malt, Maris Otter&lt;/li&gt;
&lt;li&gt;1 lb Patagonia 190&lt;/li&gt;
&lt;li&gt;9 lbs 12 oz Pilsner Liquid Extract&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hops:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1 oz Chinook for 60 mins&lt;/li&gt;
&lt;li&gt;1 oz Goldings, East Kent for 30 mins&lt;/li&gt;
&lt;li&gt;1 oz Centennial for 15 mins&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Spices:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1 oz coriander for 5 mins&lt;/li&gt;
&lt;li&gt;6 sticks cinnamon for 5 mins&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Yeast:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2 pkg Safale American #US-05&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;At the end of the brew I recorded an original gravity of 1.068. I always use a
secondary fermentation, which I switched to after 14 days.  When I moved from
primary to secondary I recorded a gravity of 1.036.  I left it in secondary for
about 4 weeks.  Unfortunately, I didn&amp;rsquo;t actually get any fermentation in
secondary. Come bottling day I had a final gravity of 1.036.&lt;/p&gt;

&lt;h3 id=&#34;the-result&#34;&gt;The result&lt;/h3&gt;

&lt;p&gt;Drum roll please &amp;hellip; Today is the first tasting day and I am moderately happy
with this batch. I will definitely have to retry the recipe later this year.
This beer came out fairly sweet with a spicy flavor in the back of the mouth.
I was originally a little nervous about the cinnamon but it is not overly
powerful.  The coriander is subtle.&lt;/p&gt;

&lt;h3 id=&#34;bottom-line&#34;&gt;Bottom line&lt;/h3&gt;

&lt;p&gt;Ultimately, I always look at my winter beers as a my big experiment and this
year was a mixed result.  I think it is probably sweater than I would like.
About a month ago I finished a red ale and I think I prefer that one over this
porter, but I wont be sad to drink it :)&lt;/p&gt;

&lt;h3 id=&#34;update&#34;&gt;Update&lt;/h3&gt;

&lt;p&gt;Letting the beer bottle age another week made a &lt;em&gt;huge&lt;/em&gt; difference. The extra
sweetness went away and the extra carbonation made a big difference for the
mouth feel.  I am now willing to give this beer a hearty thumbs-up!  Just make
sure you let it fully age before you crack one open.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hello</title>
      <link>http://lucasroesler.com/2017/01/hello/</link>
      <pubDate>Sun, 15 Jan 2017 00:00:00 -0700</pubDate>
      
      <guid>http://lucasroesler.com/2017/01/hello/</guid>
      <description>&lt;p&gt;Welcome! This is just a test post, a proof of life.&lt;/p&gt;

&lt;p&gt;
Future content will include a mix of technical and personal content including programming (a mix of Python, JavaScript, and Postgres), management, product, homebrew beer, and motorcycle trips.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Lucas Roesler</title>
      <link>http://lucasroesler.com/resume/</link>
      <pubDate>Fri, 21 Jun 2013 11:27:27 -0400</pubDate>
      
      <guid>http://lucasroesler.com/resume/</guid>
      <description>

&lt;h3 id=&#34;lucas-roesler&#34;&gt;Lucas Roesler&lt;/h3&gt;

&lt;p&gt;Salt Lake City, UT 84047&lt;br /&gt;
&lt;a href=&#34;mailto:roesler.lucas@gmail.com&#34;&gt;roesler.lucas@gmail.com&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://github.com/LucasRoesler&#34;&gt;https://github.com/LucasRoesler&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;technical-skills&#34;&gt;Technical  Skills&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Languages:  Python, Django, AngularJS, MongoDB, PostgreSQL, PHP, MySQL, HTML, CSS, Javascript, jQuery, R, Bash&lt;/li&gt;
&lt;li&gt;Applications:  Amazon Web Services (AWS), Git, Sage, Mathematica, LaTeX&lt;/li&gt;
&lt;li&gt;Operating Systems:  UNIX/Linux, Mac OS X, Windows&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;education&#34;&gt;Education&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Ph.D. in Mathematics&lt;/strong&gt;, &lt;em&gt;University of Connecticut (UConn)&lt;/em&gt;, Storrs, Connecticut - &lt;strong&gt;May 2012&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Dissertation Title: &amp;ldquo;Algebras from surfaces and their derived equivalences&amp;rdquo;
Advisor: Dr. Ralf Schiffler&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;M.S. in Mathematics&lt;/strong&gt;, &lt;em&gt;University of Connecticut (UConn)&lt;/em&gt;, Storrs, Connecticut - &lt;strong&gt;May 2009&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;B.A. in Mathematics&lt;/strong&gt;, &lt;em&gt;Central Connecticut State University (CCSU)&lt;/em&gt;, New Britain, Connecticut - &lt;strong&gt;May 2007&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;professional-experience&#34;&gt;Professional Experience&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Director of Engineering&lt;/strong&gt;, Teem (formerly EventBoard), Salt Lake City, Utah - &lt;strong&gt;2016 &amp;ndash; present&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Manage the workflow of the engineering team and work with stakeholders to establish project priorities and timelines.&lt;/li&gt;
&lt;li&gt;Work with Support to troubleshoot and resolve or assign issues.&lt;/li&gt;
&lt;li&gt;Support and drive development and adoption of architectural, coding, and security standards/governance.&lt;/li&gt;
&lt;li&gt;Contribute to the development of the product roadmap to prioritize features/projects.&lt;/li&gt;
&lt;li&gt;Manage and grow our team of developers.&lt;/li&gt;
&lt;li&gt;Build and maintain dev tooling.&lt;/li&gt;
&lt;li&gt;Backend development.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Python - Django - PostgresSQL - AWS&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Lead Developer&lt;/strong&gt;, EventBoard, Salt Lake City, Utah - &lt;strong&gt;2015 &amp;ndash; 2016&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Django web development.&lt;/li&gt;
&lt;li&gt;Designed and built user management and permissions systems.&lt;/li&gt;
&lt;li&gt;Designed API documentation system using Swagger.&lt;/li&gt;
&lt;li&gt;Increase database migration stability.&lt;/li&gt;
&lt;li&gt;Manage development teams.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Python - Django - PostgresSQL - AWS&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Lead Developer&lt;/strong&gt;, JobDash, Salt Lake City, Utah - &lt;strong&gt;2013 &amp;ndash; 2015&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;AngularJS and Django web development.&lt;/li&gt;
&lt;li&gt;Designed and built an analytics system in PostgreSQL and MongoDB.&lt;/li&gt;
&lt;li&gt;Manage and implement development processes for a team of developers.&lt;/li&gt;
&lt;li&gt;Manage server uptime and deployment on AWS and DigitalOcean with Fabric.&lt;/li&gt;
&lt;li&gt;Decrease page load times by a factor of 10.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Python - Django - AngularJS - PostgreSQL - MongoDB - AWS - LaTeX&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Software developer&lt;/strong&gt;, SAIC, Tucson, Arizona - &lt;strong&gt;2013&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Researched and implemented new feature detection algorithms in Python and C++.&lt;/li&gt;
&lt;li&gt;Managed the transition of projects from CVS and SVN to Git.&lt;/li&gt;
&lt;li&gt;Implemented hooks to enforce guidelines and workflow procedure.&lt;/li&gt;
&lt;li&gt;Implemented new features for active websites in Django.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Python - Django - C++ - Git&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Web developer&lt;/strong&gt;, &lt;em&gt;Pedegogy in Large Lectures&lt;/em&gt;, UConn, Storrs, Connecticut - &lt;strong&gt;2011 &amp;ndash; 2012&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Designed, created, and managed the webpage, videos, surveys, and raw data reports
for the Pedagogy in Large Lectures research project.&lt;/li&gt;
&lt;li&gt;Managed the transition to new developers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;PHP - MySQL - Javascript - LaTeX&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Web developer&lt;/strong&gt;, &lt;em&gt;Mathematics Department&lt;/em&gt;, UConn, Storrs, Connecticut - &lt;strong&gt;2009 &amp;ndash; 2012&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Created secure forms for administrative use.&lt;/li&gt;
&lt;li&gt;Updated and created new secure forms for student use.&lt;/li&gt;
&lt;li&gt;Implemented basic security for existing web forms.&lt;/li&gt;
&lt;li&gt;Created extensive user and developer documentation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;PHP - MySQL - Javascript&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;public-projects&#34;&gt;Public Projects&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Django Encrypted Json Field&lt;/strong&gt; - &lt;a href=&#34;https://github.com/LucasRoesler/django-encrypted-json&#34;&gt;https://github.com/LucasRoesler/django-encrypted-json&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Store JSON in Postgres with encrypted values and plain text keys.&lt;/li&gt;
&lt;li&gt;Allows partial encryption, you can specify a list of keys to skip.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Django Cryptographic Fields&lt;/strong&gt; - &lt;a href=&#34;https://github.com/foundertherapy/django-cryptographic-fields&#34;&gt;https://github.com/foundertherapy/django-cryptographic-fields&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Contributions to allow key rotation and general improvements.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;other-experience&#34;&gt;Other Experience&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Visiting Instructor in Mathematics&lt;/strong&gt;, &lt;em&gt;Lebanon Valley College&lt;/em&gt;, Annville, Pennsylvania &lt;strong&gt;2012 &amp;ndash; 2013&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Finite Mathematics - Calculus 1 - Differential Equations&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Teaching Assistant&lt;/strong&gt;, &lt;em&gt;UConn&lt;/em&gt;, Storrs, Connecticut - &lt;strong&gt;2007 &amp;ndash; 2012&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Discrete Mathematics - Mathematical Modeling - Calculus 1a - Calculus 1 - Calculus 2 - Business Calculus&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Research Assistant&lt;/strong&gt;, &lt;em&gt;Pedagogy in Large Lectures&lt;/em&gt;, UConn, Storrs, Connecticut - &lt;strong&gt;2011 &amp;ndash; 2012&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Integrated online videos and flashcards to improve learning in large lectures. Created content for, implemented, and maintained the web resources for displaying content and collecting survey data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Implementation of Crystals of Generalized Young Walls&lt;/strong&gt;, a method to construct combinatorial mathematical objects called crystals in the open source computer algebras system &lt;a href=&#34;http://www.sagemath.org/&#34; title=&#34;Sage&#34;&gt;Sage&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Source available at &lt;a href=&#34;https://bitbucket.org/Theaxer/sage&#34;&gt;https://bitbucket.org/Theaxer/sage&lt;/a&gt;
Accepted for inclusion into the Sage combinat branch: &lt;a href=&#34;http://trac.sagemath.org/sage_trac/ticket/14130&#34;&gt;http://trac.sagemath.org/sage_trac/ticket/14130&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Python - Sage&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;publications&#34;&gt;Publications&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;L. David-Roesler. &lt;em&gt;The AG-invariant for m-angulations&lt;/em&gt;, submitted, available online: &lt;a href=&#34;http://arxiv.org/abs/1210.6087&#34; title=&#34;arXiv:1210.6087&#34;&gt;arXiv:1210.6087&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;L. David-Roesler. &lt;em&gt;Derived Equivalence in Surface Algebras via Graded Equivalence&lt;/em&gt;, 30 pages, to appear in Algebr. Represent. Theory. &lt;a href=&#34;http://link.springer.com/article/10.1007%2Fs10468-012-9384-9&#34; title=&#34;doi:10.1007/s10468-012-9384-9&#34;&gt;doi:10.1007/s10468-012-9384-9&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;L. David-Roesler and R. Schiffler. &lt;em&gt;Algebras from surfaces without punctures&lt;/em&gt;. J. Algebra 350 (2012). pp. 218-244. &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S0021869311006211&#34; title=&#34;doi:10.1016/j.jalgebra.2011.10.034&#34;&gt;doi:10.1016/j.jalgebra.2011.10.034&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;interests&#34;&gt;Interests&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Rock climbing/bouldering, home brewing, music (bass guitar and listening), hiking, reading, tabletop gaming, and participating in open source projects (Ubuntu, Gnome, Gedit).&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>